
# BiGAT-Fusion Â· Bidirectional Graph Attention with Node-wise Gated Fusion for Drugâ€“Disease Association Prediction

[![License: MIT](https://img.shields.io/badge/License-MIT-lightgrey.svg)](#-license)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red.svg)
![OS](https://img.shields.io/badge/OS-Linux%20%7C%20macOS%20%7C%20Windows-555.svg)

> ğŸš€ Official PyTorch implementation of our paper: "BiGAT-Fusion: Bidirectional Graph Attention with Node-wise Gated Fusion for Drugâ€“Disease Association Prediction".
---

## âœ¨ Highlights

- ğŸ§  **Two-view encoders**: feature-view GAT (drug/drug & disease/disease kNN graphs) + topology-view **Bi-GAT** (drugâ‡„disease).
- ğŸ”€ **Node-wise gated fusion**: type-specific gates adaptively mix feature and topology embeddings per node.
- ğŸ§© **Residual-MoE head**: MLP main path + **low-rank bilinear** residual with a bounded pairwise gate.
- ğŸ§ª **Rigorous CV**: 10Ã—10 cross-validation; validation-driven LR scheduling; BCE with negative sampling.
- ğŸ“Š **Artifacts for analysis**: per-fold metrics, checkpoints, attentions (both directions), and fusion gates.

---

## ğŸ—‚ï¸ Repository Structure

```
.
â”œâ”€â”€ data_loader.py    # Dataset loading + kNN feature graphs + CV-friendly splitting
â”œâ”€â”€ bigat_model.py    # BiGAT-Fusion model (encoders + gated fusion + Residual-MoE)
â”œâ”€â”€ run_fullcv.py     # 10Ã—10 CV training/evaluation
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
# (optional) create a fresh environment
python -m venv .venv

# Linux/macOS
source .venv/bin/activate

# Windows
# .venv\Scripts\activate

# Install requirements
pip install -r requirements.txt
```
âœ… **Minimal requirements**: `numpy`, `pandas`, `scipy`, `scikit-learn`, `torch` (â‰¥1.12)

### ğŸ§° Data Formats

The loader supports four common DDA benchmark formats:

- **C/G .mat** (`Gdataset.mat`, `Cdataset.mat`)  
  Required variables:
  - `didr` (association matrix; some distributions store it as [disease, drug])
  - `disease` (diseaseâ€“disease similarity)
  - `drug` (drugâ€“drug similarity)
  - `Wrname` (drug names)
  - `Wdname` (disease names)

- **Ldataset** (CSV directory)  
  Files:
  - `dis_sim.csv`, `drug_sim.csv`, `drug_dis.csv`

- **LRSSL** (TSV directory)  
  Files (tab-separated):
  - `dis_sim.txt`, `drug_sim.txt`, `drug_dis.txt`

ğŸ“ Place datasets under `datasets/` and reference them via `--mat_path`.

---

## â–¶ï¸ Reproduce 10Ã—10 CV

```bash
python run_fullcv.py --mat_path data/Gdataset/Gdataset.mat --folds 10 --repeats 10 --device cuda
```

### ğŸ”§ Key Defaults
- ğŸ” **Negative sampling**: `neg_k=3` (training uses unweighted BCE; the batch prior comes from sampling)
- ğŸ¯ **Attention normalization**: destination-wise stabilized softmax (subtract a batchwise constant)
- ğŸª« **Weight decay**: backbone `1e-4`, gates `1e-3`
- ğŸ“‰ **LR scheduling**: `ReduceLROnPlateau` on validation AUROC
- âœ‚ï¸ **Gradient clipping**: `5.0`; **Dropout**: `0.2`

### ğŸ“¤ Outputs
- `results/<dataset>/cv_log_full.csv` â€” per-fold AUROC/AUPRC
- `train/full_<dataset>_r<R>_f<F>.pt` â€” best checkpoints
- `interpret/folds/<dataset>/full/r<R>_f<F>.npz` â€” attentions (drugâ†’disease & diseaseâ†’drug) and node-wise gates

---

---

## ğŸ§ª Reproducibility

We set seeds and:
```python
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```
Minor numerical differences can occur across hardware/BLAS stacks; metrics are robust to small jitter.

---

## ğŸ§± Model Components (at a glance)
- **Feature-view encoders**: GAT over kNN graphs built from similarity matrices
- **Topology-view encoder**: Bi-GAT, with direction-specific attentions (drugâ†’disease, diseaseâ†’drug)
- **Fusion**: type-specific node-wise gates for adaptive mixing of views
- **Decoder**: Residual-MoE â†’ MLP(main) + Î³ Â· (low-rank bilinear) + node biases

---

## ğŸ“œ License
Released under the MIT License â€” see `LICENSE`.
